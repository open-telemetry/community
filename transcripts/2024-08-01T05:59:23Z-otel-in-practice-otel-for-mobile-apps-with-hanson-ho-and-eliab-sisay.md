# OTel in Practice: OTel for Mobile Apps with Hanson Ho and Eliab Sisay

Published on 2024-08-01T05:59:23Z

## Description

Missed our live OTel in Practice? No problem! Catch our replay right here! Learn how Embrace rebuilt their native Android and ...

URL: https://www.youtube.com/watch?v=mTcdwdWIFgI

## Summary

In this episode of "Otel and Practice," hosts Hansen and Eliah from Embrace discuss the challenges and opportunities of implementing data modeling and observability in mobile app design, particularly through the lens of OpenTelemetry (otel). Eliah introduces the concept of mobile observability, emphasizing the need for developers to monitor app performance in real-time to enhance user experience. Hansen elaborates on the unique complexities of mobile environments, such as diverse hardware and software configurations, session tracking issues, and the limitations of traditional observability tools. The presentation highlights the differences between mobile and backend systems, the importance of user-centric metrics, and ongoing efforts to standardize mobile observability practices. The session concludes with a call to action for developers interested in contributing to the mobile observability ecosystem through various OpenTelemetry Special Interest Groups (SIGs).

# Otel in Practice: Mobile Data Modeling and Observability

[Music]

**Welcome to another edition of Otel in Practice!** Today, we have Hansen and Eliah from Embrace to discuss the challenges and opportunities of data modeling and application design in mobile apps. While OpenTelemetry often focuses on backend systems, we will explore its application in client-side environments.

### Presentation Overview

We will begin with a presentation followed by a Q&A session. Please feel free to drop your questions in the chat, or add them to the Agile Coffee board I’ve set up. We will review the questions at the end of the talk.

Without further ado, I'll hand it over to Hansen, who will kick things off. 

**Hansen:** Thanks! I'm actually going to pass it off to Eliah to get us started.

### Introduction by Eliah Cisi

Hi everyone! My name is Eliah Cisi, and I am a product manager at Embrace. We are a mobile observability company that provides developers with SDKs to integrate into their mobile apps for real-time performance monitoring. Our main goal is to help developers keep their apps running smoothly by proactively identifying and resolving issues, ultimately improving the overall user experience.

We are heavily invested in OpenTelemetry, having begun our transition about nine months ago. This transition has helped us provide our customers with a unified and comprehensive view of app performance, from what happens client-side on the user's mobile device all the way to the backend services that power those experiences.

While the benefits of OpenTelemetry are numerous, we have encountered specific challenges when implementing it in a mobile environment, which is what we will discuss today. 

On the call, we also have Hansen, an Android architect at Embrace and a former mobile performance engineer at Twitter. Hansen will be doing most of the presentation today.

### Mobile App Usage Statistics

Let’s set some context. In 2022, the average mobile user spent a little over four hours a day on their phones, with over 90% of that time spent in native mobile apps. By the end of this year, mobile apps are expected to generate over $900 billion in revenue. If you think about your own mobile use, it’s likely that the brands or companies you interact with have a native app that you use consistently.

Over the past 5 to 10 years, we’ve worked to improve observability for backend systems, creating various standards, notably OpenCensus and OpenTracing, which form the foundation of OpenTelemetry. However, mobile apps differ significantly from distributed systems. They are installed software running on distributed compute resources that interact with distributed systems, presenting unique challenges.

For instance, session tracking in the mobile world can range from several seconds to several hours and may be interrupted by phone calls, network changes, or the app running in the background. Furthermore, the mobile ecosystem is highly fragmented, with multiple operating systems and countless device manufacturers. 

One customer of ours reported over 42,000 different combinations of device models and chipsets that could exist, making it clear how complex mobile observability can be.

Historically, monitoring and observability in the mobile ecosystem have largely been proprietary systems, often starting with Firebase Crashlytics, which, while free, is highly sampled and limited in features. Serious app developers often seek more robust solutions.

When discussing customer experience, we find that many customer-impacting Service Level Objectives (SLOs) are tied to the mobile device. Unfortunately, many developers lack adequate information that correlates this data with their work on backend reliability and resiliency.

### Challenges and Opportunities in Mobile Observability

Now, I’ll hand it off to Hansen to discuss some challenges and opportunities we face today.

**Hansen:** Thank you, Eliah. I’m here to talk about how mobile is different in terms of observability. The crux of the problem is often about moving tooling onto mobile platforms and making them run effectively. 

There are fundamental differences in the assumptions we make about durability and the questions we ask of our tooling. Without identifying these differences, we can’t start improving the specifications or tools.

### Key Differences in Mobile Observability

1. **Dynamic Runtime Environment**: Mobile devices have unique, unpredictable environments with over 42,000 device combinations. The runtime is dynamic; for example, losing a mobile connection while in an elevator can affect app performance.

2. **Fragility of Data Capture and Transmission**: Transmitting data from mobile devices to servers can be fragile. Data can be lost due to crashes or unstable network connections, leading to incomplete information.

3. **User Experience-Centric Data**: Observability on mobile focuses on the user experience. Each measurement corresponds to a unique user instance, making it more than just a system health check.

### OpenTelemetry Considerations

Now, let’s talk about OpenTelemetry. It works well as a lingua franca of observability, but its backend roots mean it was designed for a specific context. When we apply it to mobile, some parts don’t fit well.

- **Spans**: While spans are great for measuring application operations in predictable environments, they may not be effective in mobile contexts where operations can be disrupted by crashes or interruptions.

- **Telemetry Reliability**: OpenTelemetry assumes telemetry is reliably recorded and transmitted. However, that’s not necessarily the case in mobile environments.

- **Resource Strain**: Mobile devices, especially lower-end models, may struggle with the resource strain that telemetry recording and transmission can cause.

- **Understanding of Low-Level Concepts**: Many mobile engineers may not understand low-level concepts like threads or context propagation, making it important to adapt APIs for broader usability.

- **Execution Boundaries**: Mobile app operations can span several modules owned by different teams, making instrumentation brittle without the right infrastructure.

- **Independent Instances**: Mobile devices are independent instances, which complicates how we aggregate metrics and could limit their usefulness.

### Conclusion and Call to Action

In conclusion, we’re working on addressing these challenges and would love to involve more people interested in mobile observability. Hansen is involved in the Android and client-side special interest groups (SIGs), and we have people working on Swift SIG as well. If you’re interested, we welcome your contributions!

Thank you for your time! We’ll now open the floor for questions.

---

### Q&A Session

**Question 1:** In web, Core Web Vitals have become a standard for measuring user experience. Do you see an emerging standard for mobile apps?

**Hansen:** Yes, we are working on modeling certain metrics for mobile applications, particularly around sluggishness and performance. We want to collaborate with the SIGs to define these standards.

**Question 2:** What about applications using Kotlin Multiplatform (KMP)? What are the instrumentation options available?

**Hansen:** KMP is similar to React Native. Currently, there isn’t a native SDK for KMP that emits OpenTelemetry telemetry. We’re evaluating how best to approach this and see potential in KMP, but we need an SDK to get started.

**Question 3:** How closely related is mobile instrumentation to browser instrumentation in tracking user journeys?

**Hansen:** There are more similarities between mobile and browser apps than between mobile and backend distributed traces. We should consider best practices in both areas.

**Question 4:** Do different types of mobile apps require different kinds of data models?

**Hansen:** Yes, different apps may require specific semantic conventions. For example, gaming apps may need to track frame rates closely, while social media apps may focus more on engagement metrics.

**Question 5:** Do you have ideas on golden signals for mobile apps, irrespective of device type or OS version?

**Hansen:** The ultimate golden signal is whether the user is happy. Metrics like user return rates and operation success rates are critical.

**Question 6:** Any thoughts on resource utilization metrics like CPU or memory for mobile apps?

**Hansen:** Resource utilization can be tricky on mobile, as other apps and the OS can affect performance. It’s crucial to capture contextual information for it to be useful.

**Question 7:** When might OpenTelemetry mobile instrumentation be ready for production use?

**Hansen:** It’s ready now, depending on your specific needs. There are SDKs available, and some apps are already in production using these solutions.

**Closing Thoughts:**

We encourage everyone to get involved with mobile observability discussions in the SIGs. The ecosystem is continuously evolving, and your insights can help shape its future.

Thank you for joining us today, and we hope to see you in future editions of Otel in Practice! 

[Music]

## Raw YouTube Transcript

[Music] well hello everyone uh welcome to another edition of otel and practice and today we've got Hansen and Eliah from Embrace uh they're going to take us through some of the challenges and some of the opportunities as well of doing a data modeling AP design in mobile apps so in open Telemetry we talk a lot about back end but uh we'll see how we can apply open Telemetry to the client site as well so um we will do a presentation first and then there will be time for Q&A and dropp in a link in the chat and then I've created a agile coffee board you can go there you can add your questions and then at the end of a talk we'll go through the Q&A can vote for your questions as well so feel free to add your questions as you're as you see in the presentation and then we'll go through them at the end so without further Ado um I'll introduce Hansen I think you're going to be picking off um so take it away great I'm actually going to pass it off to elab to kick it off nice uh hi everyone yeah like uh it was mentioned my name is elab cisi I am a product manager at Embrace uh you can go next slide Hansen we are a mobile observability company um we provide developers with sdks that they can integrate into their mobile apps to monitor performance in real time and our main goal really is to help developers keep their apps running smoothly by proactively identifying and resolving issues really with the objective of improving the overall user experience um we're also heavily uh invested in open Telemetry uh we began that transition about nine months ago and it's really helped us provide our customers with a more unified and and comprehensive view of app performance from what's Happening client side on the user's mobile device all the way to the backend services that power those experiences um and in doing that migration we discovered that while the benefits of open Telemetry are numerous there are some specific challenges that occur when trying to implement it in a mobile environment and that's kind of what we're here to to talk about today and I'll be honest and say that the term we is very generous um also on the call is Hansen um who we talked about he's an Android architect at Embrace formerly a mobile performance engineer at Twitter so I'm just here to do kind of a brief intro and then I'll hand it off to Hansen who will be doing uh a majority of of the presentation um next slide thank you um one more so I want to start by just setting a little bit of context so in 2022 uh the average mobile user spent a little over four hours a day on their phone and of that over 90% of of it or about 90% of it was within native mobile apps and by the end of this year mobile apps are expected to generate over 900 billion dollars in in revenue and if you yourself think about your own mobile use I'm willing to bet that the brand or companies that you interact with most have a native app that you use consistently now as we think about the observability ecosystem we've spent the last 5 to 10 years really trying to figure out how we do observability better for for backend systems and there are a variety of standards that were created uh most notably open census and open tracing which form the foundation for where we are today with open Telemetry to provide the visibility into the health of distributed systems um but mobile apps are not a distributed system they are installed software running on distributed compute resources that interact with distributed systems and there's a lot of unique challenges with that environment um take session tracking for instance uh in the mobile World a user session can be anything from several seconds to several hours and it can be interrupted by calls or network changes or the app running in the background which is really quite different from what you see server side mobile apps themselves are also extremely different like a gaming app for example needs to track things like frame rate and rendering times while a financial app might focus more on transaction speeds and and security events add to that the fragmentation in the mobile ecosystem where you've got multiple operating systems and countless device manufacturers and it's really easy to see how complex that becomes um we uh were looking at a number at the number of unique devices for just one customer and we saw that there was like 42,000 plus different combinations of device models and chipsets that could potentially exist which is you know crazy um and for most of its life cycle like observability and monitoring in the mobile ecosystem has been mostly proprietary systems designed by vendors like the typical starting point is Firebase crash lytics which is free but highly sampled and extremely Limited in its feature set so if you're a serious app developer you're not going to use that and that's led to a bunch of vendors building their own proprietary standards and trying to convince people that they should be serious about observability with their solution but mostly it's just crash reporting and error tracking and so the result is that the Paradigm looks something like this and the unfortunate thing is that a lot of mobile Engineers actually consider that to be kind of acceptable um but when we talk to customers who truly care about the user experience that their customers are having on their mobile devices they tell us that all of their customer impacting slos are directly tied to the mobile device but they don't have a good source of information that correlates that data to the work they're doing to build reliability and resiliency in their backend systems um and so that's what Hansen's going to be talking about which is some of the challenges in this Paradigm that we're facing today um and some of the opportunities and and how we're working to address that um but more than anything I think today is really a call to action for the people in the zoom for the people watching if you yourself or if you have co-workers or people that are interested in the mobile ecosystem we would love for you guys to get involved Hansen's involved in the Android Sig and the client side Sig we have people working in the Swift Sig uh we're working on otel contributions for react native and flutter and we're really committed to making mobile observability as robust and standardized as it is for for backend systems and we'd love to involve as many of you in that effort as possible um so uh with that I'll hand it off to to Hansen thanks aab so I am here to talk about how make how mobile is different in terms of observability I think the the first thing to approach this is that the the Crux of the problem is actually about simply moving uh tooling onto these mobile platforms and making them run because there are fundamental differences that are embedded in the assumptions that we make uh when we have durability and the questions that we ask of our tooling and without first identifying and acknowledging these differences we can't start improving the specs or or tooling because we don't know what it should look like you know to make the front of the horse uh look like the back of the horse we got to First figure out what the the face should be and and here is what I'm trying to do is is just to to go over a little bit what the differences may be uh I can spend a couple hours here talking about this but hey we don't have that much time so I'm just going to concentrate this in in three general areas where mobile is different first is the runtime environment we're talking about Dynamic heterogeneous runtime environments running you know devices that are unpredictable 42,000 unique chipsets and and device combinations not only that the environment that they run in is extremely dynamic as well you walk into an elevator and you lose your mobile connection you lose your network connection you back around the app to answer a notification that affects how the operating system runs the app not only that the actual Hardware that is running your app is quite severely limited phones exists 10 years ago still even Ed today pH are released last year that cost $99 and well the hardware uh mirrors that cost and the OS not only limits what you could do with that already limited Hardware it also does it in a very unpredictable way so what you have is is a dynamic environment where you don't know what is actually executing your app and not only that objective performance which is typically what we measure is only part of the equation because what makes nap slow differs in terms of where I'm using it or whether somebody else is using it perceived performance is also part of the equation and slos have to somehow take that into account another aspect of mobile that makes it challenging and different than backend is the fragility of the capture and transmission pipeline how to get data from these devices onto servers I could do something with it data could be lost in multiple stages uh before it gets captured because it was a crash uh before you persist the data or after we persist the data uh because the network connection is unstable and we can't get the data over to the server and even when the server gets the data it could be delayed or out of order so what you get may not be the full picture until several hours later when more data comes in thank you network connections and lastly the data we capture has to Center the user experience because operational runtime in device state is useful only in how they provide insight into individual user experiences end to end otherwise it's just trivia on mobile we're observing millions of independent app instances but each one of the measurements we get maps back to user it is not merely a state of health of the system if something is slow somebody is looking at a very slow phone it's like a P99 what does that mean well P99 is 1% of all measurements are that slow or slower so if you think that's an outlier well 1% of of of interactions being that slow means it is more than an outlier it is something that we have to capture now let's talk about otel so in general otel tell it works really well as a lingual franka of observability uh its backend Roots though mean that it was designed to solve a problem with a very specific context and when we change that context to mobile you know some part starts to not fit very well and these are the ones I'm going to talk about so first let's talk about spans spans are great on hotel if you want to measure the duration of operations of applications that have a very fix uh runtime environment um predictable runtime code path uh so you can actually measure and calculate deviations based on some baselines they are not so great if say duration is not an indicator of performance if you want to measure a period of time um well otel signal to use looks like it's spans but is it because duration is not an indicator of performance and you start aggregating and say hey what's P95 that starts to not make sense also operations run for a long time in otel well unfortunately you don't get to know what happened until it ends either in a failure uh or success but what if it gets interrupted middle uh through a crash that we don't know about uh mobile apps could be killed without actually alerting the app so operations like that are gone or lost uh and with otel itself we wouldn't know about it because it's not done and that's kind of challenging for mobile also operations that need to be contextualized with a lot of mutable State um that are expensive to obtain well that's a challenge because in in otel you write the data into the spans of span events or uh or attributes um but sometimes the act of getting these types of State takes a while uh for the mobile app to actually get from the OS and for us to basically block the the ending of a of a trace um just the right nute that's not fantastic the second point I want to talk about is that the protocols and apis of votel make certain assumptions that are just not true on mobile now for example assumption one is that Telemetry is recorded and transmitted reliably and you could trust that data that gets recorded will make make it to the server the collector in a in a reasonable amount of time but as we mentioned before that is not true in Mobile and it could also may not be true in a number of fascinating ways so tooling that that is usable on mobile has to take that into account and build a resilience like dis persistence for instance before export um you know thanks to Cesar for doing that on uh open Java or the open cry Android extension it's extremely helpful to in production um in the future perhaps there's a be place for ways for us to automatically transmit uh a group of related Telemetry so that we don't get into this you know uh uh weird state in the back end wondering if more data is coming that'd be nice another assumption is that recording and transmitting Telemetry doesn't put a strain on system resources the SDK are well written um and they perform well so on the back end use them it's no problem however on low-end devices and meter networks uh it means that every signal captured reduces and potentially reduces performance or cost users money so we have to be ex a lot more careful in how we uh record data and how we transmit data and even even simply the act of getting the data to record can be expensive so the consideration that we have to you know go into what to record is I think a lot greater and depends on the use case another assumption is that Engineers that use the API understand lowlevel Concepts like threads or or or context propagation um even the idea of tracing uh and what spans are um may not be universally understood if you change the audience to mobile Engineers simply because the background the variety of background of folks building mobile apps changes quite a bit it could be somebody who's just done a six-month boot camp who is building you know a mobile app for the local grocery store um and they want observability too they want to know why their stuff is slow but they're used to higher level constructs uh like Coe routines when you're using threads but not really they don't know about it and how do you explain propagation when they don't understand the the existence of a thread so adapting the apis to be Ematic is one thing but making those Concepts understandable by those without CS backgrounds that's a another challenge right there and lastly another assumption is that traced operations have a clear execution boundary um and code ownership so you have a service that creates a span and the runtime you know generally a team owns that you know you know uh front to back and you transmit the context via context propagation etc etc as you would in distributed tracing unfortunately things are not as clean on mobile because a single span for an operation can go through several modules owned by several teams and not all of them may be aware of all these problems so instrumentation can be extremely brittle if you don't have the right infrastructure in place to catch you know regressions where implementation changes but the instrumentation doesn't um it's not as modular nicely connected cleanly connected as you would for distributed Trace just because of of how mobile apps are architected and the last otel thing I'm going to talk about is that mobile devices are millions of independent instances uh an otel generally assumes that the system being monitored and observed is is one connected system um it could be made of uh dozens of microservices deployed in various ways but effectively they all roll up um and metrics in that context makes a lot of sense otel metrics but for mobile when we have disconnected app instances running that starts to break down because metrics need to be grounded in the context of the system that Ms them in order for the baselines to be created and compared and munging together uh metrics from phones of various models into one limits how useful those generated metrics are what does P95 of uh Heap size of an app at one minute mean when you look at the entire you know Fleet of devices I don't know did it when it changes when increases or decreases is that good or bad well I don't know because we don't know the reasons because these are different systems and not that metrics aren't useful on mobile they're extremely useful but you tend to need to have like to like comparison Apples to Apples and it tends to involve Dimensions that are high in cardinality and unfortunately that just doesn't work fantastically well with lotel metrics um and also just simply the strict time aligned aggregation is not really suitable for apps that have operations that have variable duration and have data come in at any time uh it it just wasn't meant to do what mobile wants it to do but that's okay because these are not insurmountable challenges these are these are ongoing things that we could s that we could work with uh the the protocol and and the sigs and the folks to to kind of you know improve so we're working with the in in with various sigs to try to you know get some of these problems surface and address um we are also you know you know at Embrace uh having workaround to go around otel or perhaps use otel in um uh I would say non-standard ways in order to get the data to to do what we wanted to do um but that's not the end State the end State we want to see is a diverse ecosystem and tooling that builds on uh not only what folks in Nel have done before but also extends support the plethora of use cases that we're bringing up and and frankly this is just the beginning because mobile apps that I'm familiar with run on very small restricted you know uh set of circumstances and phones and tablets is what I'm I'm used to using I I haven't worked on cars or TVs iot um but those apps deserve observability as well and I'm sure as we as we take the tooling and the in the spec forward more use cases will come on the board and say hey hey I want to I want to connect my data from my TV to my backend data well what what challenges additional challenges are there when I don't even know how a TV Works in terms of uh how it uses Android but I'm sure it's different and I'm sure there are new things um and at this point we're just exploring ourselves we're we're trying to ask questions we're trying to figure out if our assumptions are correct are there things we could change about how we used to do things and order to fit more into otel but at the end of the day we want everyone to kind of come up with their use cases and and help ask these questions um of mobile and client use cases for otel um great work has been done in the Android and Swift and and client Sig already but I think there could be more going forward um and folks listening maybe the converted the Bing otel but hopefully other people also watch this and say hey you know what I looked at otel it didn't really fit but after this presentation maybe maybe I can make it fit maybe I can use it in a way that is productive and actually truly have this become the lingual franer of observability for both the back end and the front end so that's enough of us talking um any questions uh I'm gonna end the presentation if I can there we go thank you very much Hansen um for those that have joined a bit later maybe haven't seen this message we've got an agile coffee board you can your questions in there um think we've got a couple of questions uh we'll start with one uh related to uh so we've got um in web cwe vitals have become a standard to measure user experience for better Awards do you see an emerging standard to measure equivalent Concepts in mobile apps for sluggishness or speed yes uh so you know with with Motel everything is defined effectively as semantic conventions built on the existing signals um and on and embrace we've kind of modeled some of the T Rec capture for things like anrs on Android uh uh and various other kind of Mobile you know slowness sluggishness um we did it in a certain way that you know it works but is it the best we don't know um but once once we figure it out we'll want to you know work with the sigs to to submit conventions uh to to model that and uh I believe especially with the introduction of these um you know emerging specs of of profile profiling and and even entities a lot of these problems that we have are going to be addressed um so it's it's a matter of uh figuring out what we have and then defining them and if you're interested in you know defining certain uh uh slowness uh metrics and or you know metrics Telemetry uh you know for mobile you know let's talk uh there's one that's I'm in the middle of putting together with the help of a lot of folks from the the client s um a crash uh uh stic convention um that spans platforms that's different from exceptions uh that we have many more down the pipe and is limited by the the abandonments that we have uh but anything that can be should be standardized in as semantic inventions so it's a very long way of saying yes and please help good stuff uh let's go on to another one um there are some options available for otel instrumenting iOS or Android code what about applications using cotlin multiplatform what instrumentation options are available any additional considerations when instrumenting KMP so C multiplatform is interesting uh I mean for those unfamiliar it's it's similar to to you know react native or things like that where you write it once and it kind generates na native apps um for the various platforms um I'm sure I'm getting something wrong in the technicality there but the idea is that you have one codebase multiple platforms um there isn't an SDK that I'm aware of uh that works in such a way that is built natively into cotland multiplatform um that will emit Hotel Telemetry uh whenever we have iOS or Android Android we use a Java SDK uh you know at the core and iOS uses the Swift SDK um to have cotland multiplatform either there has to be a native SDK for cot multiplatform in cotlin only that will you know transpile into the native platforms um so not only IOS and Android there's you know web and whole bunch of different platforms or there has to be a way of getting um a bridge built to the other sdks um we are we are evaluating you know at Embrace at least we're evaluating um how best to approach this um we think the native way is is the best way um but we don't know we're working through some of these problems um not specifically multiplatform but with react native um which is I think why more well known and more well adopted um so uh there's definitely uh opportunity in C multiplatform um but first we got to have an SD before we got to have a way of getting otel Telemetry working on that platform like recording first before anything else can happen so if if you're working on it you know you should start talking to people think about that because that' be really I'd be interested as well thank you I think the next question is about one of your challenges sounds like one of the core challenges for mobile observability is the variability of runtime environments software and Hardware is this entirely an open problem or are there suggestions on how to start tackling this so I think I to do it natively in otel um I think entities will have to if for for those who are who may not be familiar with that that particular working group The entities working group is is a way of I guess capturing um external mutable transition of of States um that independent from but related to apps um and I think for us we could see it capturing a lot of this variable State um without having to directly you know uh well actually the implementation is not yet I don't know maybe it could work um we have done certain things that we're not super uh uh I mean we've done certain things to work around this um that may not be accept or or enatic uh so we're using uh spans uh to log uh I guess durations of of interesting things happening um and then on the back end kind of you know merging the stuff all together uh that's not great but also say it also allows us to capture the stuff independently um and not have uh Telemetry recording be blocked um and also not have to like encode every change of network condition onto every piece of telemetry sent and have race conditions that will you know especially on mobile apps uh make the the edges blurry um so we have something working um but we're not sure if it's the best quite yet and we're really looking for entities um you know being able to do that um or help us does that answer your question I think there were two parts I might have only answer one part I'm assuming so oh uh I think we've got a few questions so I'm going to move to the next one um I know that you're part of the uh the the client side instrumentation seg so this was quite interesting one how closely or not is mobile instrumentation to browser instrumentation as far as tracking user Journeys for example if the client side instrumentation work gear towards one or the other or are the data models for both browser and mobile considered the same or similar enough I think there are differences but certainly there are a lot more similarities with uh uh web uh web apps and mobile apps then I would say uh between mobile apps and backend distributed traces um I think the differences are are more nuanced and I think there's enough similarity that anything that we should consider for web we should consider for mobile and vice versa uh there may be cases where you know it is immediately you know un uh you know this doesn't fit um but honestly you can you could run a mobile application on a mobile browser honorable device so all the environmental changes uh are are effectively uh similar that they have to deal with um so I think in that respect um they are very very similar so yeah we work very closely with the web folks moving on um what different types of mobile apps require different K kinds of data models um for example an online gaming like magic the Gathering versus a social media app like Instagram or a messaging app oh so the question is um do does it or yeah do they do they require different kinds of data models those different types of apps certainly different semantic conventions I would say um and also there are certain characteristics about the runtime that is more interesting to uh High frame rate apps like games for instance um if you using a you know I don't know Salesforce online uh frame rate you know scroll Jank is bad but you know it doesn't deter from the experience that much and also it's not as sensitive to say mobile device capabilities but if you're running a un game and your frame rate drops by half uh in critical instances you want to know about it so having refined having more um detailed data for that kind of stuff will be applicable to certain domains and not others um but I think that becomes more of a a challenge of tooling and instrumentation rather than the the spec um I think the spec as it is you know with with you know logs and spans well events actually specifically I think um and and and spans and hopefully a way of classifying spans in the future um they give us enough of the building blocks to to model these you know different use cases um so the same challenges that we have in terms of transmission things like that as long as those dealt with um I think a good portion of that stuff is is is going to be taken care of now there may be additional things that I I'm not aware of that will certainly need to to to to have different types of consideration um but I think I think before we run let's just crawl and I think getting uh unity and others those those different apps that that we may not typically think about console apps for instance you have McDonald's and you have that thing that opens for 24 hours that's a different use case than a mobile app that you background all the time after seconds um I think I think with with with the the work that we're doing now hopefully we we we'll move things forward enough so that uh we can start looking at some of these you know more more challenging uh issues like uh frame rates um on on on unity and things like that I think this one this next one relates back to some of the um earlier questions but you mention that duration is not an indicator of performance are there golden signals for mobile irrespective of device type an OS version or do we always need to take these factors into consideration I think the golden signal is whether the user is happy or not um and on on mobile uh there are indicators of whether user is happy in terms of uh whether they actually come back and use the the app again um so things like you know simply da whether the user comes back a usage rate um because just because one operation is slow it the effects could be multiplied if you have many many many many instances these slow operations you basically get fed up with the app so you know at the at the very end the very highest level whether the app is being used is a good indicator but um going lower level because that that that that level is is almost too late sometimes whether an operation succeeded um users tend to give up on operations if they things take too slow uh to load they they you know they background the app or they uh or they you know hop to another page or whatever it is so looking at abandoned rate um of of of uh of operations as usful if you're tracking you know whether particular operation is taking too long um so looking at duration in those cases even if duration is important um abandon rate is actually super important as well because you can actually have a case where your p50 p 5 goes down because more people give up so your success rate reduces uh and and you're and you're uh and your and your performance increases you're like what's that well it's because people are it's so slow people are giving up so the population is is different underneath you're you're losing people already so all the people are remaining are the fast people and in fact this is actually a key problem in Mobile performance is that people look at the current state and you're like oh yeah P99 that looks great well you haven't considered people who are for whom your app is way too slow and you can't even use it or they use it they install it it's too slow they uninstall it so you naturally filter out a whole bunch of users that would otherwise want to use your app but it's just too darn slow so this this kind of self-filling Prophecy of oh I don't have to invest um in apps because people experience uh uh them experience some high quality fast well it's because you've lost all the people and the inability to trap those to track those you've lost is is a huge I think Miss um in in Mobile observability and I think otel we have facilities um to track it uh we can't end a spand you know with with a unsuccessful ending so data can be collected to to take care of this use case and I think that to me is the most important thing to track is is not just duration it's whether or not it actually succeeded can I can I add just one other thing there just from my product hat here I think it the the golden signals that are asked in that question really depend on the type of app that you have so Hansen talk about startup and abandon rate and slow frame rates all of those can have different impacts on your users depending on the intent of your app whether it's like we talked about this earlier whether it's a gaming app or a financial services app or you know whatever that may be so if I were you know PM or working on a on a mobile app you should really go back to what are the primary key workflows that we need our users to do to make this a successful transaction and I use that term very broadly for them and then you go instrument those based on whatever that is so you know for a gaming app your golden signal may be frame rate because you know if your frame rate is as high as possible and your users are having um a really frictionless experience you see gameplay time increase you see all these other second order effects um really turn into uh uh really have positive impacts on those second order effects whereas retail app it's really about checkout right like how fast is that checkout flow for me are the operations that are that blay are checkout flow are they performant um are they reliable Etc so it really really depends on what your app is is trying to do and also the audience is important too like are they using your app because they have to um or are they using your app because they choose to if you're a game and you're slow while I can just play another game if if your if your workplace uses Microsoft oh no shouldn't say uh uses certain apps that you have no choice but to use um you know what yeah slow but you don't you don't have a choice so the golden signal there may be a little bit less than than if if folks are have have more options to go um next question I think this is yeah specific type of app as well uh do you know of some uh use cases of otel working on video streaming apps like Netflix not that I'm aware of um and if they exist it would be I think the instrumentation would be fairly bespoke because o no not that I'm aware of but it would be very interesting use case um I think we've got two more um resource utilization like CPU or memory is normally uh represented as a gauge in a Time metric um time CDs format um on a backend system do time series make sense in mobile apps at all certain time series uh I would say utilization less so um because the app is not the only utilizer of resources um uh and you could be running very you know expectedly and something higher priority the OS decides to schedule somebody you know starts a video in the corner of their tablet they have multiscreen enabled and suddenly the the fast cores are now going to the uh to the uh mobile tablet video and well your app is running and suddenly things are slow SL suddenly you are getting issues or you didn't get before um it's good to to track the the utilization of the CPU but there are probably other things you would want to know about like that that the utilization is supposed to tell you so I think the key is is can the utilization tell you information that you can't get otherwise um and I think on mobile there are just so many different things that could affect utilization um that you almost need to capture so much other contextual information for that to be useful that if you're going to do that you may as well go direct and say Hey you know uh are are we seeing lag are we seeing failures are we seeing unexpected occurrences um in in in the app um in certain instances and knowing that your app is not being prioritized that's important but you know how big of the Heap is for instance you know the Dos changes that on you so much it it you it'll GC you know out of in the most inappropriate places um simply because it wants more uh resources for other apps it'll kill your app in the background uh because another app is running and needs it and it's no fault of yours that your thing got killed faster it's something else that affects it so res socialization there may be use cases where it's useful but I think for me uh it's it's harder to use the data makes sense I think this this is the last question we've got um do you have some idea of when otel mobile instrumentation might be ready for use and production is it months is it years it's ready now depends on what you want to do uh there is uh sdks out there um you know directly the Swift SDK and the and the the various JavaScript SDS so if you want to kind of roll your own it works um the Android uh open your Android project is something Dr drag you know just drop it in your app and it'll kind of do some monitoring for you uh the Embrace sdks uh you can actually use it without using embrace you can just drop it in um configure your uh your exporters to go to your own collectors um use our implementation of of the tracing API uh to you know have instrumentation libraries you like data sessions and have it all sent to your your own your own servers without Embrace being involved uh there are I mean I'm sure there are other implementations out there as well but it depends on what you want and what you need you there are things off the shelf you can use for free and you can also roll your own with the sdks um all the challenges I was talking about really is is to build a platform that is encompassing of of all the corner cases that we want to support for our you know all our customers um if you have a specific app with a specific use case with a specific thing you want to measure um you may not need any of this other stuff and and and so also if you not share in that code if you're just kind of using it on your own well who cares about stantic conventions if no one else is going to look at that data um now you're you're quite locked in to your own instrumentation which is not a good thing but if it works for you it works for you so I would go ahead and and Fork some of these repos and just try it out they should work they they do work there are apps that are in in production with all of these sdks So Co I think that's so that's all we had so um thank you very much Hansen leab um is there any closing thoughts anything you would like to to add to finish off um I mean I just go back to kind of where we started this and I think as Hansen's been talking about through this at all is that um we really really really want to get more people involved who care about mobile um in uh the working groups in the sigs like we are opinionated and we come to it with our own experiences and the work that we've done but we're by no means the the uh you know final Arbiter of what is right and wrong in Mobile and the the only way we can work through those is having a variety of use cases um and I think that Netflix question is a good example of one that we don't deal with a lot and so we may not be close to all the intricacies that come with running a video service at that scale or or other services at that scale and so um if you uh care about mobile leave even if you not be working directly on it or if you have teams that work directly on it we would love for you guys to get involved in the sigs and and provide your perspective and input yeah the ecosystem is is is just IM merging I think for mobile there I think isn't enough diversity there AR enough kind of you know folks leveraging the sdks and and then build instrumentations for uh for Mobile use cases and mobile libraries that are popular um I think the closing thought is that if you're using otel or or if your backend is using otel and you're not um you could actually get a lot of mileage just by having talking the same language and using the same signals um I used to not think there was a ton of overlap um in terms of like well just mobile folks can just have that data and then backend folks all you have to do is encode all your your your your uh your your conditionals and conditions and your requests in the back has all that data right well it's not so easy to ingest all that crap um in a performant way at every request so I've come around to understanding the utility of having two separate sets of data that can be connected um and I think this is what it does um so if you're if you're a backend person um and your company has mobile apps um that you know use unnamed uh observability companies that may be free or maybe very not free um but that don't really talk to your backend signals well have a look at otel and see what you can get in terms of of of things that that are frankly even better especially if it's provided by folks who only do mobile um there are a lot of things that are not captured um if you just use you know folks that well I forget it I'm not gonna never blah blah blah yes join us I guess that's the thing join us on the cncf LA I'll post the link in the in the channel otel client site Telemetry we also have the otel seg and user Channel if you're an end user and you want to discuss more things about how you're approaching open Telemetry so uh yeah thanks again uh both Hansen and eliab and uh we'll hopefully see you in the next edition of fotel and practice thank you bye-bye [Music]

